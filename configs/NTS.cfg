# Please fill this to your needs
# for Neural Text Simplificatio models
# Documentation: http://opennmt.net/OpenNMT/options/train/
log_file = ${PATH_TO_LOGS}
save_model = ../models/nts
data = ${PATH_TO_DATA .t7 format}
gpuid = 1,2,...,n or 0, depending on the number of GPUs

# For word2vec models
pre_word_vecs_dec = ${WORD_EMB_DEC}
pre_word_vecs_enc = ${WORD_EMB_ENC}

## Vec options
fix_word_vecs_enc = 0
feat_vec_size = 20
fix_word_vecs_dec = 0
tgt_word_vec_size = 500
word_vec_size = 0
feat_vec_exponent = 0.7
src_word_vec_size = 500

# Epoch and batch specifications
start_epoch = 1
end_epoch = 14
start_iteration = 1
uneven_batches = false
max_batch_size = 64
curriculum = 0
async_parallel_minbatch = 1000
save_every = 5000
report_every = 50

# Hyperparameters
seed = 3435
param_init = 0.1
max_grad_norm = 5

## Learning rate
learning_rate = 1
learning_rate_decay = 0.7
min_learning_rate = 0

## Decay
decay = default
start_decay_at = 7
start_decay_ppl_delta = 0

## Dropout
dropout_input = false
dropout = 0.3

## Hardware options
fallback_to_cpu = false
fp16 = false
disable_mem_optimization = false
no_nccl = false
async_parallel = false

# Model specifications
layers = 2
model_type = seq2seq
optim = sgd
rnn_type = LSTM
rnn_size = 500
global_attention = general
attention = global
residual = false
feat_merge = concat
input_feed = 1

## Sample options
sample = 0
sample_w_ppl_max = -1.5
sample_w_ppl = false
sample_w_ppl_init = 15

## BRNN options
brnn_merge = sum
pdbrnn_reduction = 2
pdbrnn = false
brnn = false
dbrnn = false

# Log
disable_logs = false
profiler = false
log_level = INFO
h = false
md = false

# Network
exp_host = 127.0.0.1
exp_port = 8889

# Unused
train_from = 
save_config = 
exp = 
config = 

# Miscellaneous
continue = false
